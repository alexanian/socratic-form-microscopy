---
id: 414
title: Against Moral Intuitions
date: 2017-06-05T18:08:43-04:00
author: Zach
layout: post
guid: https://socratic-form-microscopy.com/?p=414
permalink: /2017/06/05/against-moral-intuitions/
inline_featured_image:
  - "0"
categories:
  - Ethics
  - Philosophy
tags:
  - charity
  - someone else probably came up with this first
  - utilitarianism
---
[Content Warning: Effective Altruism, the Drowning Child Argument]

I'm a person who sometimes reads about ethics. I blame Catholicism. In Catholic school, you have to take a series of religion courses. The first two are boring. Jesus loves you, is your friend, etc. Thanks school. I got that from going to church all my life. But the later religion classes were some of the most useful courses I've taken. Ever. The first was world religions. Thanks to that course, "how do you know that about [my religion]?" is a thing I've heard many times.

The second course was about ethics, biblical analysis, and apologetics. The ethics part hit me the hardest. I'd always loved systematizing and here I was exposed to Very Important Philosophy People engaged in the millennia long project of systematizing fundamental questions of right and wrong under awesome sounding names, like "utilitarianism" and "deontology".

In the class, we learned commonly understood pitfalls of ethical systems, like that Kantians <a href="https://www.youtube.com/watch?v=x_uUEaeqFog">have to tell the truth to axe murderers</a> and that utilitarians <a href="https://www.youtube.com/watch?v=bOpf6KcWYyw">like to push fat people in front of trains</a>. This introduced me to the idea of philosophical thought experiments.

I've learned (and wrote) a lot more about ethics since those days and I've read through a lot of thought experiments. When it comes to ethics, there seems to be two ways a thought experiment can go; it can show that an ethical system conflicts with our moral intuitions, or it can show that an ethical system fails to universalize.

Take the common criticism of deontology, that the Kantian moral imperative to always tell the truth applies even when you could achieve a much better outcome with a white lie. The thought experiment that goes with this point asks us to imagine a person with an axe intent on murdering our best friend. The axe murderer asks us where our friend can be found and warns us that if we don't answer, they'll kill us. Most people would tell the murderer a quick lie, then call the police as soon as they leave. Deontologists say that we must not lie.

Most people have a clear moral intuition about what to do in a situation like that, a moral intuition that clashes with what deontologists suggest we should do. Confronted with this mismatch, many people will leave with a dimmer view of deontology, convinced that it "gets this one wrong". That uncertainty opens a crack. If deontology requires us to tell the truth even to axe murderers, what else might it get wrong?

The other way to pick a hole in ethical systems is to show that the actions that they recommend don't <em>universalize</em> (i.e. they'd be bad if everyone did them). This sort of logic is perhaps most familiar to parents of young children, who, when admonishing their sprogs not to steal, frequently point out that they have possessions they cherish, possessions they wouldn't like stolen from them. This is so successful because most people have an innate sense of fairness; maybe we'd all like it if we could get away with stuff that no one else could, but most of us know we'll never be able to, so we instead stand up for a world where no one else can get away with the stuff we can't.

All of the major branches of ethics fall afoul of either universalizability or moral intuitions in some way.

<a href="https://plato.stanford.edu/entries/ethics-deontological/">Deontology</a> (doing only things that universalize and doing them with pure motives) and utilitarianism (doing whatever leads to the best outcomes for everyone) both tend to universalize really well. This is helped by the fact that both of these systems treat people as virtually interchangeable; if you are in the same situation as I am, these ethical systems would recommend the same thing for both of us. Unfortunately, both deontology and utilitarianism have well known cases of clashing with moral intuitions.

<a href="https://plato.stanford.edu/entries/egoism/#2">Egoism</a> (do whatever is in your self-interest) doesn't really universalize. At some point, your self-interest will come into conflict with the self-interest of other people and you’re going to choose your own.

<a href="https://plato.stanford.edu/entries/ethics-virtue/">Virtue ethics</a> (cultivating virtues that will allow you to live a moral life) is more difficult to pin down and I'll have to use a few examples. On first glance, Virtue ethics tends to fit in well with our moral intuitions and universalizes fairly well. But virtue ethics has as its endpoint virtuous people, not good outcomes, which strikes many people as the wrong thing to aim for.

For example, a utilitarian may consider their obligation to charity to exist as long as poverty does. A virtue ethicist has a duty to charity only insofar as it is necessary to cultivate the virtue of charity; their attempt to cultivate the virtue will run the same course in a mostly equal society and a fantastically unequal one. This trips up the commonly held moral intuition that the worse the problem, the greater our obligation to help.

Virtue ethics may also fail to satisfy our moral intuitions when you consider the societal nature of virtue. In a world where slavery is normalized, virtue ethicists often don't critique slavery, because their society has no corresponding virtue for fighting against the practice. This isn't just a hypothetical; Aristotle and Plato, two of the titans of virtue ethics <a href="http://www.bbc.co.uk/ethics/slavery/ethics/philosophers_1.shtml">defended slavery in their writings</a>. When you have the meta moral intuition that your moral intuitions might change over time, virtue ethics can feel subtly off to you. "What virtues are we currently missing?" you may ask yourself, or "how will the future judge those considered virtuous today?". In many cases, the answers to these questions are "many" and "poorly". See the opposition to ending slavery, opposition to interracial marriage, and opposition to same-sex marriage for salient examples.

It was so hard for me to attack virtue ethics with moral intuitions because virtue ethics is remarkably well suited for them. This shouldn't be too surprising. Virtue ethics and moral intuitions arose in similar circumstances – small, closely knit, and homogenous groups of humans with very limited ability to affect their environment or effect change at a distance.

Virtue ethics work best when dealing with small groups of people where everyone is mutually known. When you cannot help someone half a world away, it really only does matter that you have the virtue of charity developed such that a neighbour can ask for your help and receive it. Most virtue ethicists would agree that there is virtue in being humane to animals – after all, cruelty to other animals often shows a penchant for cruelty to humans. But the virtue ethics case against factory farming is weak from the perspective of the end consumer. Factory farming is horrifically cruel. But it is not <em>our </em>cruelty, so it does not impinge on <em>our </em>virtue. We have outsourced this cruelty (and many others) and so can be easily virtuous in our sanitized lives.

Moral intuitions are the same way. I'd like to avoid making any claims about <em>why</em> moral intuitions evolved, but it seems trivially true to say that they exist, that they didn't face strong negative selection pressure, and that the environment in which they came into being was very different from the modern world.

Because of this, moral intuitions tend to only be activated when we see or hear about something wrong. Eating factory farmed meat does not offend the moral intuitions of most people (including me), because we are well insulated from <a href="https://thingofthings.wordpress.com/2017/02/02/why-be-vegetarian/">the horrible cruelty of factory farming</a>. Moral intuitions are also terrible at spurring us to action beyond our own immediate network. From the excellent satirical essay <a href="http://slatestarcodex.com/2013/05/17/newtonian-ethics/">Newtonian Ethics</a>:
<blockquote>Imagine a village of a hundred people somewhere in the Congo. Ninety-nine of these people are malnourished, half-dead of poverty and starvation, oozing from a hundred infected sores easily attributable to the lack of soap and clean water. One of those people is well-off, living in a lovely two-story house with three cars, two laptops, and a wide-screen plasma TV. He refuses to give any money whatsoever to his ninety-nine neighbors, claiming that they’re not his problem. At a distance of ten meters – the distance of his house to the nearest of their hovels – this is monstrous and abominable.

Now imagine that same hundredth person living in New York City, some ten thousand kilometers away. It is no longer monstrous and abominable that he does not help the ninety-nine villagers left in the Congo. Indeed, it is entirely normal; any New Yorker who spared too much thought for the Congo would be thought a bit strange, a bit with-their-head-in-the-clouds, maybe told to stop worrying about nameless Congolese and to start caring more about their friends and family.</blockquote>
If I can get postmodern for a minute, it seems that all ethical systems draw heavily from the time they are conceived. Kant centred his deontological ethics in humanity instead of in God, a shift that makes sense within the context of his time, when God was slowly being removed from the centre of western philosophy. Utilitarianism arose specifically to answer questions around the right things to legislate. Given this, it is unsurprising that it emerged at a time when states were becoming strong enough and centralized enough that their legislation could affect the entire populace.

Both deontology and utilitarianism come into conflict with our moral intuitions, those remnants of a bygone era when we were powerless to help all but the few directly surrounding us. When most people are confronted with a choice between their moral intuitions and an ethical system, they conclude that the ethical system must be flawed. Why?

What causes us to treat ancient, largely unchanging intuitions as infallible and carefully considered ethical systems as full of holes? Why should it be this way and not the other way around?

Let me try and turn your moral intuitions on themselves with a variant of a famous thought experiment. You are on your way to a job interview. You already have a job, but this one pays $7,500 more each year. You take a short-cut to the interview through a disused park. As you cross a bridge over the river that bisects the park, you see a child drowning beneath you. Would you save the child, even if it means you won't get the job and will have to make due with $7,500 less each year? Or would you let her drown and continue on the way to your interview? Our moral intuitions are clear on this point. It is wrong to let a child die because we wish to more money in our pockets each year.

Can you imagine telling someone about the case in which you don't save the child? "Yeah, there was a drowning child, but I've heard that Acme Corp is a real hard-ass about interviews starting on time, so I just waltzed by her." People would call you a monster!

Yet your moral intuitions also tell you that you have no duty to prevent the malaria linked deaths of children in Malawi, even you would be saving a child's life at exactly the same cost. <a href="http://www.cbc.ca/news/business/wealthiest-1-earn-10-times-more-than-average-canadian-1.1703017">The median Canadian family income is $76,000</a>. If a family making this amount of money donated 10% of their income to the <a href="https://www.againstmalaria.com/Default.aspx">Against Malaria Foundation</a>, they would be able to prevent one death from malaria <a href="https://docs.google.com/spreadsheets/d/1TZ-9eP0et9eYPRj2il4l1UCGS3xmqWarucW5UKQCBIU/edit#gid=115155829">every year or two</a>. No one calls you monstrous for failing to prevent these deaths, even though the costs and benefits are exactly the same. Ignoring the moral worth of people halfway across the world is practically expected of us and is directly condoned by our distance constrained moral intuitions.

Your moral intuitions don't know how to cope with a world where you can save a life half the world away with nothing more than money and a well-considered donation. It's not their fault. They didn't develop for this. They have no way of dealing with a global community or an interconnected world. But given that, why should you trust the intuitions that aren't developed for the situation you find yourself in? Why should you trust an evolutionary vestige over elegant and well-argued systems that can gracefully cope with the realities of modern life?

I've chosen utilitarianism over my moral intuitions, even when the conclusions are inconvenient or <a href="http://lesswrong.com/lw/kn/torture_vs_dust_specks/">truly</a> <a href="http://lesswrong.com/lw/n3/circular_altruism/">terrifying</a>. You can argue with me about what moral intuitions say all you want, but I'm probably not going to listen. I don't trust moral intuitions anymore. I can't trust anything that fails to spur people towards the good as often as moral intuitions do.

Utilitarianism says that all lives are equally valuable. It does not say that all lives are equally easy to save. If you want to maximize the good that you do, you should seek out the lives that are cheapest to save and thereby save as many people as possible.

To this end, I've taken the <a href="https://www.givingwhatwecan.org/try-giving">"Try Giving" pledge</a>. Last September, I promised to donate 10% of my income to the most effective charities for a year. This September, I'm going to take the full <a href="https://www.givingwhatwecan.org/">Giving What We Can</a> pledge, making my commitment to donate to the <a href="http://www.givewell.org/">most effective charities</a> permeant.

If utilitarianism appeals to you and you have the means to donate, I'd like to encourage you to do the same.

<em>Epistemic Status: I managed to talk about both post-modernism and evolutionary psychology, so handle with care. Also, Ethics.</em>